{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks.tracers.langchain import wait_for_all_tracers\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "tracer = LangChainTracer(project_name=\"new-project-langsmith-101\")\n",
    "import uuid\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a truthful AI assistant,\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "llm_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (prompt | llm_model | output_parser).with_config(\n",
    "    {\n",
    "        \"tags\": [\"openai-chat\", \"simple-chain\"],\n",
    "        \"metadata\": {\"user_id\": str(uuid.uuid4())},\n",
    "        \"run_name\": \"chat-openai-chain\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic approach to call the chain\n",
    "################################################\n",
    "response = chain.invoke({\"input\":\"What is the best way to work with Large Language Models?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly recommended approach to call the chain\n",
    "################################################\n",
    "from langchain import callbacks\n",
    "try:\n",
    "    with callbacks.collect_runs() as cb:\n",
    "        response = chain.invoke({\"input\":\"What is the best way to work with Large Language Models?\"},\n",
    "                    config= {\"callbacks\": [tracer]},\n",
    "                #  {\"tags\": [\"openai-chat\", \"simple-chain\"],\n",
    "                #   \"metadata\": {\"user_id\": str(uuid.uuid4())}}\n",
    "                )\n",
    "        run_id = cb.traced_runs[0].id\n",
    "        \n",
    "        client.create_feedback(\n",
    "            run_id=run_id,\n",
    "            key=\"user-rating\",\n",
    "            score=0.8,\n",
    "            comment=\"The response was helpful.\"\n",
    "        )\n",
    "finally:\n",
    "    wait_for_all_tracers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('a3a444fe-817d-4a03-bfe8-04d791d36979')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Working with Large Language Models can be a complex task, but here are some best practices to help you effectively work with them:\\n\\n1. Data Preparation: Ensure that your training data is clean, relevant, and diverse to help the model learn patterns effectively.\\n\\n2. Model Selection: Choose the right pre-trained language model that fits your specific use case and fine-tune it on your dataset if necessary.\\n\\n3. Fine-Tuning: Fine-tune the pre-trained model on your specific task or domain to improve its performance and adapt it to your needs.\\n\\n4. Hyperparameter Tuning: Experiment with different hyperparameters such as learning rate, batch size, and optimizer to optimize the model's performance.\\n\\n5. Evaluation: Evaluate the model's performance using appropriate metrics and test datasets to ensure it meets your requirements.\\n\\n6. Monitoring: Continuously monitor the model's performance and make adjustments as needed to maintain its accuracy and effectiveness.\\n\\n7. Ethical Considerations: Be mindful of ethical considerations such as bias, fairness, and privacy when working with large language models.\\n\\nBy following these best practices, you can effectively work with Large Language Models and leverage their capabilities to achieve your goals.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt-streamlit-600Io1P--py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
